{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchaudio\n",
    "# !pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Whisper model from Hugging Face\n",
    "whisper_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-tiny\")\n",
    "\n",
    "# Configure audio settings\n",
    "SAMPLERATE = 16000  # Whisper expects 16kHz sample rate\n",
    "CHANNELS = 1\n",
    "\n",
    "# Function to capture and transcribe audio\n",
    "def transcribe_audio(indata):\n",
    "    audio_np = indata[:, 0].astype(np.float32)\n",
    "    waveform = torch.tensor(audio_np)\n",
    "    transcription = whisper_model(waveform)\n",
    "    return transcription['text']\n",
    "\n",
    "# Streamlit UI setup\n",
    "st.title(\"Voice Transcription App\")\n",
    "st.write(\"Record your voice, and the app will transcribe it using Whisper.\")\n",
    "\n",
    "# Audio recording button\n",
    "record_button = st.button(\"Start Recording\")\n",
    "\n",
    "# Display transcription\n",
    "transcription_text = st.empty()\n",
    "\n",
    "if record_button:\n",
    "    with st.spinner(\"Recording...\"):\n",
    "        # Record for 5 seconds (You can change this)\n",
    "        audio_data = sd.rec(int(SAMPLERATE * 5), samplerate=SAMPLERATE, channels=CHANNELS)\n",
    "        sd.wait()  # Wait for recording to finish\n",
    "        \n",
    "        # Transcribe the audio\n",
    "        transcription = transcribe_audio(audio_data)\n",
    "        \n",
    "        # Display transcription\n",
    "        transcription_text.write(f\"**Transcription:** {transcription}\")\n",
    "        \n",
    "        time.sleep(1)  # Pause for smooth UI transition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
